# 不确定推理

Owner: 柒柒在笔记
课程: 人工智能原理

# 5.1 不确定推理表示、问题、分类

## 5.1.1 不确定性推理的表示

### 知识的不确定性表达

### 证据的不确定性表达

## 5.1.2 不确定性的语义问题

## 5.1.3 不确定性的计算问题

1. **不确定性匹配算法与阈值**
2. **组合证据不确定性计算方法**
    1. 最大最小法
    2. 概率法
    3. 有界法
3. **不确定性传递算法**
4. **结论不确定性的合成**

## 5.1.4 不确定性推理方法的分类

### 模型方法

**模型方法在推理一级对确定性推理进行拓展，引入证据与知识的不确定性，以某种度量标准进行相互对照**

- 数值方法
    - 基于概率
        - 概率方法
        - 可信度方法
        - 主观贝叶斯
        - 证据理论方法
    - 基于模糊理论
- 非数值方法

### 控制方法

控制方法通过识别在系统中引起不确定性的某些特征及相应的控制策略来限制/减少不确定性对系统的影响

- 启发式搜索
- 相关性制导回溯

# 5.2 不确定性的推理方法

## 5.2.1 概率方法

### 经典概率方法

IF E THEN H

E：证据 H：结论

此时条件概率可以用于表示规则的静态强度

$$
P(H|E)=\frac{P(HE)}{P(E)}
$$

### 逆概率方法

经典概率方法在实际实践中较难实现，采用逆概率实现,

$$
P(H_i|E_1,E_2,\cdots,E_m)=\frac{P(H_i)P(E_1|H_i)P(E_2|H_i)\cdots P(E_m|H_i)}{\sum_{j=1}^n P(H_j)P(E_1|H_j)P(E_2|H_j)\cdots P(E_m|H_j)}
$$

## 5.2.2 主观贝叶斯

将主观经验与贝叶斯公式进行结合

### 概率基础

- 全概率公式
- 贝叶斯公式

在事情已经方式的条件下，贝叶斯可以用于寻找导致事件B发生的原因A的概率

### 主观贝叶斯

1. **知识的不确定性表示**
    1. 使用（LS，LN）进行描述
    2. LS为充分性度量
        
        $$
        LS=\frac{P(E|H)}{P(E|\neg H)}
        $$
        
    3. LN为必要性度量
        
        $$
        LN=\frac{1-P(E|H)}{1-P(E|\neg H)}
        $$
        
    4. 实际使用中，LS与LN由专家给出
    5. 几率函数O(x)为证据X出现与不出现的概率之比
        
        $$
        O(x)=\frac{P(x)}{1-P(x)}
        $$
        
    
    几率似然性公式：
    
    $$
    O(H|E)=LS \cdot O(H)
    $$
    
    必要似然性公式：
    
    $$
    O(H|\neg E)=LN \cdot O(H)
    $$
    
    LS与LN的约束条件
    
    - LS表示来E对H的支持程度，LN表示E不存在时对H的影响程度
    - LS>1时，表明E导致H为真跌可能性增加，LS=1时二者无关，LS=0时E的存在是H位假
    - LN>1时，表示非E支持H，LN=1时二者无关，LN<1时表示非E不支持H
    - 二者不能同时大于或小于1
2. **证据的不确定性表示**
    1. 使用C(E|S)可信度进行表示，S为观测
3. **组合证据的不确定性表示**
    1. 使用最大最小法
4. **不确定性的传递算法**
    1. 证据肯定存在时
    2. 证据肯定不存在时
    3. 证据不一定存在时
        1. 详见P136 EH公式
5. **结论不确定性的合成算法**
    
    $$
    O(H|A_1\cap A_2 \cap \cdots \cap A_n)=\frac{O(H|A_1)}{O_H}\cdot \frac{O(H|A_2)}{O_H} \cdots \frac{O(H|A_3)}{O_H} \cdot O(H)
    $$
    

### 

## 5.2.3 可信度方法

### 1.知识的不确定性表示

CF模型下，知识用产生式规则表示为：

$$
\text{IF} E\ \text{THEN}\ H [\text{CF(H,E)}]
$$

CF定义如下：

$$
\text{CF(H,E)}=MB(H,E)-MD(H,E)
$$

MB 信任增长度

$$
MB(H,E）=\frac{\max\{P(H|E),P(H)\}-P(H)}{1-P(H)}
$$

MD 不信任增长度

$$
MD(H,E)= \frac{\min\{P(H|E),P(H)\}-P(H)}{-P(H)}
$$

二者都在[0,1]区间内,且服从

$$
MD\cdot ME=0 
$$

此时可以得到CF计算式

$$
CF=MB/-MD
$$

### 2.证据的不确定性表示

同样适用CF描述证据E的不确定性

- CF(E)=-1 : 证据E肯定为假
- CF<0 : 一定程度上假
- CF=0 : 无从得知
- CF>0 : 某种程度为真
- CF=1 : 肯定为真

### 3.组合证据的不确定性

- 当组合证据是多个单一证据的合取（与
    
    $$
    CF(E)= \min \{CF(E_1),CF(E_2),\cdots,CF(E_n)\}
    $$
    
- 当组合证据是多个单一证据的析取（或
    
    $$
    CF(E)= \max \{CF(E_1),CF(E_2),\cdots,CF(E_n)\}
    $$
    
- 另外，规定
    
    $$
    CF(\neg E)=\neg CF(E)
    $$
    

### 4.不确定性的传递算法

- CF(E)=1 时，此时CF(H)=CF(H,E),说明知识强度CF(H,E) 其实其实就是在前提条件为真时结论H的可信度
- 见下式
    
    $$
    CF(H)=CF(H,E) \cdot \max\{0,CF(E)\}
    $$
    

### 5. 结论不确定性的合成

当多条知识推出具有不同可信度的相同结论时，即为

$$
\text{IF}\  E_1\  \text{THEN} \ \ H\ [CF(H,E_1)], \text{IF}\  E_2\  \text{THEN} \ \ H\ [CF(H,E_2)]
$$

对知识进行两两合成，合成方法为：

- 对每一条知识计算其CF(H)
- 按照下列公式进行合成

### 6.带阈值的可信度方法

## 5.2.4 证据理论方法

### 1.概率分配函数

- 识别框架
    - 所有考察判断的事物或者对象的集合，其中元素两两互斥
    - 其子集构成求解问题的各种解答
- 基本概率分配函数
    - 对样本空间的所有子集A
    - 令M(A)表示可信度
    - M(A)不包含A的子集的信任度，不符合概率的规则
    - 基本上由人为给出

### 2.信任函数

$$
Bel(A)=\sum_{B\sube A}M(B)
$$

即：对于集合A，其信任函数为A的所有子集的概率分配函数的累加和

### 3.似然函数

$$
Pl(A)=1-Bel(\neg A),\forall A \sube \Omega
$$

表示对A为非假的信任程度

### 4.组合规则：Dempster

$$
M= M_1\oplus M_2
$$

$$
M(A)=K-\sum_{x \cup y=A}M_1(x)M_2(y)
$$

$$
K=1-\sum_{x\cup y=\emptyset}M_1(x)M_2(y)
$$

当K不为0时，此时正交合M也是一个概率分布函数，

K为0时，说明不存在，称其为矛盾

Dempster规则下，多证据组合与递归组合是等效的

### 5.基于证据理论的不确定性推理

推理步骤如下：

1. 建立识别框架Omega
2. 对幂集定义概率分配函数
3. 计算关心的子集A的信任函数与似然函数
4. 得出结论

## 5.2.5 模糊推理方法

### 1. 模糊集合

- 模糊集合的定义
    - 模糊集合中的每一个元素赋予一个0到1之间的实数，描述其属于一个集合的强度，该实属称为元素属于一个集合的隶书度，所有元素的隶书度构成了集合的隶属函数
- 模糊集合的表示方法
    
    集合的数学描述为：
    
    $$
    A=\{[X,\mu_A(x)],x\in X\}
    $$
    
    - Zadeh表示法
        - 对离散域
            
            $$
            A=\sum_{i=1}^n\frac{\mu_A(x_i)}{x_i}
            $$
            
        - 对连续域
            
            $$
            A=\int_{x \in U}\frac{\mu_A(x)}{x}
            $$
            
    - 序偶表示法
        
        $$
        A=\{[\mu_A(x_1),x_1], [\mu_A(x_2),x_2],\cdots, [\mu_A(x_n),x_n]\}
        $$
        
    - 向量表示法
        
        $$
        A=\{\mu_A(x_1), \mu_A(x_2),\cdots, \mu_A(x_n)\}
        $$
        
- 隶属函数
    - 模糊统计法
    - 指派方法
    - 专家经验法
    - 二元对比排序法

### 2. 模糊集合的运算

- 包含关系
    
    $$
    \mu_A(x)\geq \mu_B(x),B\sube A
    $$
    
- 相等
    
    $$
    \mu_A(x)= \mu_B(x),B= A
    $$
    
- 交并补
    - 交集
        
        $$
        \mu_{A \cap B}(x)=\min\{ \mu_A(x),\mu_B(x)\}=\mu_A(x)\wedge \mu_B(x)
        $$
        
    - 并集
        
        $$
        \mu_{A \cup B}(x)=\max\{ \mu_A(x),\mu_B(x)\}=\mu_A(x)\vee \mu_B(x)
        $$
        
    - 补集
        
        $$
        \mu_{\overline{A}}(x)=1-\mu_A(x)
        $$
        
- 代数
    - 代数积
        
        $$
        \mu_{A\cdot B}(x)=\mu_A(x)\mu_B(x)
        $$
        
    - 代数和
        
        $$
        \mu_{A+B}(x)=\mu_A(x)+\mu_B(x)-\mu_{A \cdot B}(x)
        $$
        
    - 有界和
        
        $$
        \mu_{A\oplus B}(x)=\min\{1, \mu_A(x)+\mu_B(x)\}=1 \wedge[\mu_A(x)+\mu_B(x)]
        $$
        
    - 有界积
        
        $$
        \mu_{A\otimes B}(x)=\max\{1, \mu_A(x)+\mu_B(x)-1\}=1 \vee[\mu_A(x)+\mu_B(x)-1]
        $$
        

### 3. 模糊关系与合成

- 模糊关系
    - 定义R=AXB
    - 类似于矩阵运算，但是把矩阵中的乘法用取小来代替
    - 详见例题P153 5.11
- 模糊关系的合成
    - 类似矩阵运算，乘法用取小，加法用取大
    - 详见例题P154 5.12

### 4. 模糊推理规则

- 模糊命题
    - 含有模糊概念、模糊数据的语句为模糊命题
    - 表现为： x is A x is A(CF)
    - A为模糊概念，x为变量，CF为可信度
- 模糊知识表示
    - 模糊规则指条件到结论的模糊关系矩阵R
- 对IF THEN的模糊推理
    - 条件模糊集为A，结论模糊集为B
    - 计算模糊关系R
        
        $$
        R=A \circ B
        $$
        
    - 代入公式
        
        $$
        B'=A' \circ R
        $$
        
- 对 IF A is A AND…..AND y is B then z is c的推理
    - 计算输入模糊集之间的模糊关系R
    - 计算输入模糊集与输出模糊集之间的R
    - 计算蕴含关系R

### 5. 模糊决策

模糊决策又称去模糊化，模糊判决，解模糊，清晰化

- 最大隶属法
    - 只取隶书度最大的作为结果
    - 要求隶属曲线一定要是正规凸模糊集合
    - 两个及以上元素均为最大时，取平均值
- 系数加权平均判别法
    - 适合隶属曲线为梯形时
    
    $$
    U=\frac{\sum_{i=1}^n\mu(u_i)u_i}{\sum_{i=1}^n\mu(u_i)}
    $$
    
- 中位数法
    - 把隶属曲线和横坐标围成的面积平均分成两部分
        
        $$
        \sum_{u_1}^{u^*}\mu(U_i)= \sum_{U^*+1}^{U_n}\mu(U_j)
        $$
        
- 中心法
    
    $$
    U=\frac{\sum_{i=1}^N[x_i\sum_{j=1}^MF_j(x_j)]}{\sum_{i=1}^N\sum_{j=1}^M F_j(x_i)}
    $$
    

### 6. 模糊推理

1. 对各规则的前提条件，计算隶属度
2. 基于规则获得值，确定规则计算得到的结果
3. 整理成一个模糊集合
4. 进行去模糊化
5. 详见P160 例题5.16

## 章末习题

1. **简述确定性推理和不确定性推理的区别和优点**
    
    **输入信息**：
    
    - 确定性推理：输入信息和规则都是确定的。
    - 不确定性推理：输入信息和规则可能是不确定的或有噪音的。
    
    **结果形式**：
    
    - 确定性推理：结果是确定的和必然的。
    - 不确定性推理：结果是概率性的或可能性的。
    
    **处理方式**：
    
    - 确定性推理：基于逻辑推理，过程和结果明确。
    - 不确定性推理：基于概率、模糊逻辑等方法，结果具有不确定性
2. **主观贝叶斯的优点是什么，说明LS与LN的意义**
    1. 优点
        - **结合先验知识**：可以利用先验知识或经验，这在数据有限或不完全的情况下特别有用。
        - **灵活性**：允许使用各种形式的先验分布和似然函数，适应不同类型的问题和数据。
        - **一致性**：通过贝叶斯定理，新的数据可以逐步更新已有的知识体系，保持推理过程的一致性。
        - **不确定性处理**：可以自然地处理不确定性，通过概率分布表达模型的不确定性。
        - **决策理论**：提供了自然的决策框架，可以通过最大化后验概率来做出最佳决策。
    2. LS
        1. 充分性度量：表示E对H的支持程度
    3. LN
        1. 必要性度量：表示-E对H的支持程度
3. **什么是可信度，说明CF(H,E)的含义**
    1. 可信度：表现E对H的支持程度
4. **简述证据理论推理的过程，并介绍概率分配函数，信任函数和似然函数的意义**
    1. 过程：
        1. 构建样本空间
        2. 根据已知信息构建基本概率分配函数
        3. 计算K值与M
        4. 计算信任函数与似然函数
        5. 得出结果
    2. 概率分配函数：
        1. 表示对相应命题的可信度
    3. 信任函数
        1. 表示对命题A为真总的信任度
    4. 似然函数
        1.  表示对命题A为假的信任度
        
5. **举例一个身边模糊推理的过程**
    
    假设我们有一个智能温度控制系统，旨在根据当前室温调节空调的工作状态。以下是一个模糊推理的过程：
    
    1. **模糊化**：将温度传感器测量的实际温度转换为模糊集合。例如：
        - 温度 18
        18℃ 可能被模糊化为 "稍冷"（0.7） 和 "舒适"（0.3）。
    2. **规则库**：定义模糊规则来描述温度与空调状态之间的关系。
        - 规则1：如果温度是 "稍冷"，则空调状态是 "加热低"。
        - 规则2：如果温度是 "舒适"，则空调状态是 "保持"。
    3. **推理**：根据模糊规则计算模糊输出。
        - 温度 18
        18℃ 触发了两个规则，因此需要计算两个模糊输出："加热低" 和 "保持"。
    4. **解模糊化**：将模糊输出转换为具体的控制动作。
        - 通过加权平均等方法，将 "加热低"（0.7） 和 "保持"（0.3） 转换为具体的加热功率，如 "加热30%"。
    5. **控制输出**：系统根据解模糊化的结果调节空调的加热功率
6. 设有三个独立结论H1，H2，H3，以及两个独立证据E1，E2，先验概率与条件概率分别为：利用概率方法求出
7. 设有如下知识，求当证据E1,E2,E3分别存在时，
8.